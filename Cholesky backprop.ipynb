{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reverse Mode differentiation of the Cholesky Algorithm in (C|P)ython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Positive definite matrices](https://en.wikipedia.org/wiki/Positive-definite_matrix) are at the core of Gaussian process models, and are best dealt with using the [Cholesky decomposition](https://en.wikipedia.org/?title=Cholesky_decomposition), which factors a positive definite matrix $\\mathbf K$ into a lower triangular matrix $\\mathbf L$, as $\\mathbf K = \\mathbf L\\mathbf L^\\top$. Once we have $\\mathbf L$, it's much easier to solve linear systems, compute determinants, etc. Every inference method in [GPy](https://github.com/SheffieldML/GPy) uses the Cholesky decomposition. \n",
    "\n",
    "So let's say we have a matrix $\\mathbf K$, which we factor into $\\mathbf L$, and then we compute some function $f(\\mathbf L)$. For optimization of the function, we compute the derivative $\\frac{\\partial f}{\\partial \\mathbf L}$. But since $\\mathbf K$ is the primary object, we want to compute $\\frac{\\partial f}{\\partial \\mathbf K}$: this is called reverse-mode differentiation (or 'backpropagation' in machine learning parlance), and we'd usually write something like\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf K} = \\sum_{i,j} \\frac{\\partial f}{\\partial \\mathbf L}_{[i,j]} \\frac{\\partial \\mathbf L_{[i,j]}}{\\partial \\mathbf K}\n",
    "$$\n",
    "\n",
    "The problem is that $\\frac{\\partial \\mathbf L_{[i,j]}}{\\partial \\mathbf K}$ is not well defined, because there are _many_ solutions to the equation $\\mathbf K = \\mathbf L\\mathbf L^\\top$, of which the Cholesky decomposition picks only one. It turns out that the Cholesky procedure requires a series of square-roots, and by convention the positive root is selected each time: this makes it tricky to continue mathematically, but [Smith](1) shows that by considering the algorithm as a mathematical procedure, we can compute the derivative of each step and end up with the result we want. Adapting Smith's pseudocode to python results in the following.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop_gradient_pure(df_dL, L):\n",
    "    \"\"\"\n",
    "    Given the derivative of an objective fn with respect to the cholesky L,\n",
    "    compute the derivate with respect to the original matrix K, defined as\n",
    "\n",
    "        K = LL^T\n",
    "\n",
    "    where L was obtained by Cholesky decomposition\n",
    "    \"\"\"\n",
    "    df_dK = np.tril(df_dL).copy()\n",
    "    N = L.shape[0]\n",
    "    for k in xrange(N - 1, -1, -1):\n",
    "        for j in xrange(k + 1, N):\n",
    "            for i in xrange(j, N):\n",
    "                df_dK[i, k] -= df_dK[i, j] * L[j, k]\n",
    "                df_dK[j, k] -= df_dK[i, j] * L[i, k]\n",
    "        for j in xrange(k + 1, N):\n",
    "            df_dK[j, k] /= L[k, k]\n",
    "            df_dK[k, k] -= L[j, k] * df_dK[j, k]\n",
    "        df_dK[k, k] /= (2 * L[k, k])\n",
    "    return df_dK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works, and how long it takes, for a few different sizes of $\\mathbf K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 18.7 ms per loop\n",
      "1 loops, best of 3: 1.15 s per loop\n",
      "1 loops, best of 3: 18.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for N in [50, 200, 500]:\n",
    "    #create a P.D. matrix\n",
    "    A = np.random.randn(N,N+1)\n",
    "    K = np.dot(A, A.T)\n",
    "\n",
    "    L = np.linalg.cholesky(K)\n",
    "\n",
    "    #create a super simple function of L, and its derivative\n",
    "    B = np.random.randn(*L.shape)\n",
    "    f = np.sum(L*B)\n",
    "    df_dL = B\n",
    "    \n",
    "    print 'N=', N, ':'\n",
    "    %timeit backprop_gradient_pure(df_dL, L)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but is horribly slow: the majority of time is spent in Python lookups, garbage collection, and other high level stuff. \n",
    "\n",
    "One way round this is to use Cython, which allows us to eliminate that overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "#cython: wraparaound=False\n",
    "#cython: boundscheck=False\n",
    "#cython: nonecheck=False\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "def backprop_gradient_cython(np.ndarray[double, ndim=2] df_dL, np.ndarray[double, ndim=2] L):\n",
    "    cdef np.ndarray[double, ndim=2] df_dK = np.tril(df_dL).copy()\n",
    "    cdef int N = L.shape[0]\n",
    "    cdef int k, j, i\n",
    "    for k in range(N - 1, -1, -1):\n",
    "        for j in range(k + 1, N):\n",
    "            for i in range(j, N):\n",
    "                df_dK[i, k] -= df_dK[i, j] * L[j, k]\n",
    "                df_dK[j, k] -= df_dK[i, j] * L[i, k]\n",
    "        for j in range(k + 1, N):\n",
    "            df_dK[j, k] /= L[k, k]\n",
    "            df_dK[k, k] -= L[j, k] * df_dK[j, k]\n",
    "        df_dK[k, k] /= (2. * L[k, k])\n",
    "    return df_dK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 50 :\n",
      "10000 loops, best of 3: 82.8 µs per loop\n",
      "\n",
      "N= 200 :\n",
      "100 loops, best of 3: 4.01 ms per loop\n",
      "\n",
      "N= 500 :\n",
      "10 loops, best of 3: 69.8 ms per loop\n",
      "\n",
      "N= 1000 :\n",
      "1 loops, best of 3: 532 ms per loop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for N in [50, 200, 500, 1000]:\n",
    "    #create a P.D. matrix\n",
    "    A = np.random.randn(N,N+1)\n",
    "    K = np.dot(A, A.T)\n",
    "\n",
    "    L = np.linalg.cholesky(K)\n",
    "\n",
    "    #create a super simple function of L, and its derivative\n",
    "    B = np.random.randn(*L.shape)\n",
    "    f = np.sum(L*B)\n",
    "    df_dL = B\n",
    "    \n",
    "    print 'N=', N, ':'\n",
    "    %timeit backprop_gradient_cython(df_dL, L)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    [1]: http://www.tandfonline.com/doi/abs/10.1080/10618600.1995.10474671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With very little effort, cython has given us a much needed improvement. for a 500 by 500 matrix, the backpropagation procedure has gone from 18 seconds to 70 milliseconds, and we're now able to do a 1000 by 1000 matrix in about half a second.\n",
    "\n",
    "This Cython implementation is still _much_ slower than the decomposition itself though. A thought-provoking question about performance on [Stack Overflow](http://stackoverflow.com/questions/22479258/cholesky-decomposition-with-openmp) shows that the inner loops of the _decomposition_ can be parallelized. Closer inspection of the code above shows that the inner loops of the backpropagation can also be parallelized! \n",
    "\n",
    "to do this, We've use the cython parallel code, and have switched the type declarations from numpy arrays to [memoryviews](http://docs.cython.org/src/userguide/memoryviews.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cell magic `%%cython` not found.\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "#cython: wraparaound=False\n",
    "#cython: boundscheck=False\n",
    "#cython: nonecheck=False\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from cython.parallel import prange, parallel\n",
    "def backprop_gradient_cython_par(double[:,:] df_dL, double[:,:] L):\n",
    "    cdef double[:,:] df_dK = np.tril(df_dL).copy()\n",
    "    cdef int N = L.shape[0]\n",
    "    cdef int k, j, i\n",
    "    for k in range(N - 1, -1, -1):\n",
    "        with nogil, parallel():\n",
    "            for i in prange(k + 1, N):\n",
    "                for j in range(k+1, i+1):\n",
    "                    df_dK[i, k] -= df_dK[i, j] * L[j, k]\n",
    "                for j in range(i, N):\n",
    "                    df_dK[i, k] -= df_dK[j, i] * L[j, k]\n",
    "        for j in range(k + 1, N):\n",
    "            df_dK[j, k] /= L[k, k]\n",
    "            df_dK[k, k] -= L[j, k] * df_dK[j, k]\n",
    "        df_dK[k, k] /= (2. * L[k, k])\n",
    "    return df_dK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 50 :\n",
      "10000 loops, best of 3: 96.7 µs per loop\n",
      "\n",
      "N= 200 :\n",
      "100 loops, best of 3: 3.86 ms per loop\n",
      "\n",
      "N= 500 :\n",
      "10 loops, best of 3: 68 ms per loop\n",
      "\n",
      "N= 1000 :\n",
      "1 loops, best of 3: 494 ms per loop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for N in [50, 200, 500, 1000]:\n",
    "    #create a P.D. matrix\n",
    "    A = np.random.randn(N,N+1)\n",
    "    K = np.dot(A, A.T)\n",
    "\n",
    "    L = np.linalg.cholesky(K)\n",
    "\n",
    "    #create a super simple function of L, and its derivative\n",
    "    B = np.random.randn(*L.shape)\n",
    "    f = np.sum(L*B)\n",
    "    df_dL = B\n",
    "    \n",
    "    print 'N=', N, ':'\n",
    "    %timeit backprop_gradient_cython_par(df_dL, L)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don;t seem to be getting much speed up there. Looking at htop, it seems I'm only getting parallelism for a small amount of time, most of the process is single thread bound. I'm possibly doing something wrong, but it's not clear to me what that is.\n",
    "\n",
    "One nice thing that Cython allows is for inclusion of functions defined in external c files. This means I can implement the parallelism using `#pragma omp` statements myself. Here's the cython for linking in an externally defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure cython can see the external file at compile time (only needed in the notebook)\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/james/.cache/ipython/cython/_cython_magic_fd27ae7de617d79c9185fd6dbcfb7786.so: undefined symbol: chol_backprop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-90c43fa3f4ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'cython'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'--compile-args=-fopenmp --link-args=-fopenmp --compile-args=-I/home/james/work/WalkingRandomly/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'#cython: wraparaound=False\\n#cython: boundscheck=False\\n#cython: nonecheck=False\\nimport numpy as np\\ncimport numpy as np\\n\\ncdef extern from \"cholesky_backprop.h\" nogil:\\n    void chol_backprop(int N, double* df_dK, double* L)\\n\\ndef backprop_gradient_c(np.ndarray[double, ndim=2] df_dL, np.ndarray[double, ndim=2] L):\\n    cdef np.ndarray[double, ndim=2] dL_dK = np.tril(df_dL) # makes a copy, c-contig\\n    cdef int N = L.shape[0]\\n    with nogil:\\n        chol_backprop(N, <double*> dL_dK.data, <double*> L.data)\\n    return dL_dK'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/james/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/james/anaconda/lib/python2.7/site-packages/Cython/Build/IpythonMagic.pyc\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/home/james/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/james/anaconda/lib/python2.7/site-packages/Cython/Build/IpythonMagic.pyc\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_code_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_import_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: /home/james/.cache/ipython/cython/_cython_magic_fd27ae7de617d79c9185fd6dbcfb7786.so: undefined symbol: chol_backprop"
     ]
    }
   ],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp --compile-args=-I/home/james/work/WalkingRandomly/\n",
    "#cython: wraparaound=False\n",
    "#cython: boundscheck=False\n",
    "#cython: nonecheck=False\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "cdef extern from \"cholesky_backprop.h\" nogil:\n",
    "    void chol_backprop(int N, double* df_dK, double* L)\n",
    "\n",
    "def backprop_gradient_c(np.ndarray[double, ndim=2] df_dL, np.ndarray[double, ndim=2] L):\n",
    "    cdef np.ndarray[double, ndim=2] dL_dK = np.tril(df_dL) # makes a copy, c-contig\n",
    "    cdef int N = L.shape[0]\n",
    "    with nogil:\n",
    "        chol_backprop(N, <double*> dL_dK.data, <double*> L.data)\n",
    "    return dL_dK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
